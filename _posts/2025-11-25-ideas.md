---
title: "研究思路"
date: 2025-11-25
author: "Guo Haobing"
header-img: ""
tags: []
categories: [研究思路]
permalink: /posts/2025/11/ideas/
excerpt: "研究思路"
---

**文章**：Yuan Yuan, Jingtao Ding, Jie Feng, Depeng Jin, and Yong Li. 2024. UniST: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671662. Code:[https://github.com/tsinghua-fib-lab/UniST.](https://github.com/tsinghua-fib-lab/UniST)

试图提出一个基于LLM的通用城市时空预测模型。针对跨场景的不同时空数据扩展，使用时空提示词对齐跨场景的底层共享模式（不同场景的时空数据具有差异性）。

![](../images/2025-12-08-10-27-27.png)
![]({{"../images/2025-12-08-10-27-27.png"|relative_url}})

使用的是基于Transformer encoder-decoder结构的base model，将四维的时空数据 $X \in \mathbb{R}^{T×C×H×W}$ 按属性维度（通道维度C）划分为一串三维的tensor $x^{(c)} \in \mathbb{R}^{L×H×W}$ ，然后将其划分为patch，大小为(l,h,w)，并将patch使用卷积变换为一维token $E_x=Conv_{3d}(x^{(c)})$，从得到一串token序列。

encoder-decoder结构基于Masked Autoencoder(MAE)，采取了四种掩码策略，每次迭代随机选取一种掩码策略，增加数据多样性，提升模型泛化能力。
```python
mask_type = random.choice(["temporal", "spatial", "attribute", "joint"])
```

提出四个假设：
1. Spatial closeness(SC): Nearby units may influence each other.
2. Spatial hierarchy(SH): The spatial hierarchical organization impacts the spatio-temporal dynamics, requiring a multi-level perception on the city structure.
3. Temporal closeness(TC): Recent dynamics affect future results, indicating a closeness dependence.
4. Temporal period(TP): Daily or weekly patterns exhibit similarities, displaying a certain periodicity.

![](../images/2025-12-08-11-09-28.png)
![]({{"../images/2025-12-08-11-09-28.png"|relative_url}})

![](../images/2025-12-08-11-10-37.png)
![]({{"../images/2025-12-08-11-10-37.png"|relative_url}})

提示词生成，合并到transformer中进行联合学习。
![](../images/2025-12-08-11-32-27.png)
![]({{"../images/2025-12-08-11-32-27.png"|relative_url}})

![](../images/2025-12-08-11-29-59.png)
![]({{"../images/2025-12-08-11-29-59.png"|relative_url}})

**文章**：Zijian Zhang, Xiangyu Zhao, Qidong Liu, Chunxu Zhang, Qian Ma, Wanyu Wang, Hongwei Zhao, Yiqi Wang, and Zitao Liu. 2023. PromptST: PromptEnhanced Spatio-Temporal Multi-Attribute Prediction . In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM ’23), October 21–25, 2023, Birmingham, United Kingdom. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3583780.3615016

针对的是多属性时空预测，提出基于LLM的泛化，自适应，可迁移模型，计算成本低。使用参数共享训练方法，设计了插入时空特征信息中的轻量级时空令牌，并集合了LLM的常识。（工程应用）

![](../images/2025-12-05-12-50-14.png)
![]({{"../images/2025-12-05-12-50-14.png"|relative_url}})

**文章**：Zhonghang Li, Lianghao Xia, Jiabin Tang, Yong Xu, Lei Shi, Long Xia, Dawei Yin, and Chao Huang. 2024. UrbanGPT: Spatio-Temporal Large Language Models. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671578. Code:[https://github.com/HKUDS/UrbanGPT](https://github.com/HKUDS/UrbanGPT)(假开源 :punch:)（针对zero-shot的工程应用）

**动机**

时空预测在洞察城市环境的动态变化上具有独特的优势，当前存在的问题主要有城市传感场景中的数据**具有高度的稀疏性**，以此训练出来的神经网络模型无法为下游任务提供准确的指导。

LLM在推理及抽象上具有独特的优势，希望借助大模型实现在**无标签或少标签**的情况下进行准确额时空预测，以实现不同场景下较高的模型泛化能力。

***核心立意是数据稀疏问题。***

先导实验，对比不同方法预测出租车流量预测结果
![](../images/paper2xiandaotu.png)
![]({{ "../images/paper2xiandaotu.png" | relative_url }})

**基础概念**

1. 时空数据: 定义为 $X \in \mathbb{R}^{R × T × F}$ 是一个三维张量， $X_{r,t,f}$ 表示在区域r，时间t时第f个特征的值。

2. 时空预测：已知历史H个时间段的信息，预测未来P个时间段的数据：
   $$
   X_{t_{K+1}:t_{K+P}}=f(X_{t_{K-H+1}:t_{K}})
   $$
   包含两类预测预测任务：回归和分类。

3. 时空零样本学习：
   $$
   \hat{X}_{t_{K+1}:t_{K+P}}=\hat{f}(\hat{X}_{t_{K-H+1}:t_{K}})
   $$   
   模型 $\hat{f}$ 不是专门针对目标数据训练的。

**总体结构**
![](../images/paper2jiegoutu.png)
![]({{ "../images/paper2jiegoutu.png" | relative_url }})

**时间编码器**

采用门控扩张卷积和多级相关注入层（没有说具体细节），通过门控扩张卷积提取不同粒度下的时间特征，再通过多级相关注入层融合不同尺度的特征。

**时空文本对齐**

时间特征和空间特征的维度不同，通过轻量级映射模块将时空特征映射到相同的维度。（全连接层）轻量级

时空令牌：把“时空数据片段”变成类似文字 token 的向量，让 LLM 可以像读文字一样读懂时空数据。
类似如下方式：
```python
Token 1 = 0 点 A 区的 PM2.5+其它特征（映射成4096维）
Token 2 = 0 点 B 区......
Token 3 = 0 点 C 区......
...
Token 24 = 1 点 A 区......
...
Token 120 = 23 点 E 区......

```

**时空提示指令**

微调指令格式：
![](../images/paper2weitiaowenben.png)
![]({{ "../images/paper2weitiaowenben.png" | relative_url }})

**时空指令微调**

生成预测令牌，然后通过回归层映射隐藏表示以生成更准确的预测值。监督微调

回归任务：

$$
\mathbf{Y}_{r,f} = \mathbf{W}_3 \left[ \sigma(\mathbf{W}_1 \mathbf{H}_{r,f}),\; \sigma(\mathbf{W}_2 \mathbf{\Gamma}_{r,f}) \right]
$$

，其中 $\mathbf{\Gamma}_{r,f}$ 作为新术语纳入LLM的词汇表中。

**损失函数**

采用了绝对误差损失所谓回归任务函数，
将分类任务的损失也纳入进来。联合损失。

**实验评估**

指标：回归任务采用MAE和RMSE，分类任务采用召回率和宏F1分数。

数据集：NYC-taxi，NYC-bike，NYC-crime，跨城市预测采用了CHI-taxi

![](../images/paper2shiyanbiao.png)
![]({{ "../images/paper2shiyanbiao.png" | relative_url }})

**案例研究**

![](../images/paper2case1.png)
![]({{ "../images/paper2case1.png" | relative_url }})

![](../images/paper2case2.png)
![]({{ "../images/paper2case2.png" | relative_url }})

**总结**

1. 没有本质创新，采用了门控扩张卷积和多级相关性注入层联合提取时空潜在特征。
2. 针对时空预测这个新问题提出全新LLM框架。尤其是zero-shot和few-shot场景。
3. 其他的更多的是现有成熟技术的整合。

**文章**：Yuhang Liu, Yingxue Zhang, Xin Zhang, Ling Tian, Yanhua Li, and Jun Luo. 2025. UrbanMind: Urban Dynamics Prediction with Multifaceted Spatial-Temporal Large Language Models. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2 (KDD ’25), August 3–7, 2025, Toronto, ON, Canada. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3711896.3737177，code:[https://github.com/Yliu1111/UrbanMind](https://github.com/Yliu1111/UrbanMind)（假开源，代码缺失多个文件）

要解决的问题：
1. 多源异构时空数据。 
2. **训练数据和测试数据的分布差异**。
3. **不同城市场景的泛化**。
4. 可解释性。

![](../images/2025-12-08-16-53-01.png)
![]({{"../images/2025-12-08-16-53-01.png"|relative_url}})

使用了和UniST相似的MAE掩码自编码器结构，采用了三种**掩码策略**：
1. 通道敏感的空间掩码策略， $|\mathcal{M}_{\text{spatial}}|=p_s\cdot l^2$
   ![](../images/2025-12-08-18-00-17.png)
   ![]({{"../images/2025-12-08-18-00-17.png"|relative_url}})
2. 通道敏感的时间掩码策略，
   ![](../images/2025-12-08-18-02-31.png)
   ![]({{"../images/2025-12-08-18-02-31.png"|relative_url}})
3. 全局掩码策略。 $|\mathcal{M}_{\text{spatial}}|=p_s\cdot C \cdot l^2$
   ![](../images/2025-12-08-18-03-35.png)
   ![]({{"../images/2025-12-08-18-03-35.png"|relative_url}})

将当前的多面数据和目标城市的时空变量联合嵌入得到ST-Token

![](../images/2025-12-09-11-07-35.png)![](../images/2025-12-09-11-07-48.png)
![]({{"../images/2025-12-09-11-07-35.png"|relative_url}})![]({{"../images/2025-12-09-11-07-48.png"|relative_url}})

通过**语义感知提示词模块**将ST-Token封装到结构化提示词中，具体的过程和实现没有说，只有一个模块图。

![](../images/2025-12-09-11-17-29.png)![](../images/2025-12-09-11-17-40.png)
![]({{"../images/2025-12-09-11-17-29.png"|relative_url}})![]({{"../images/2025-12-09-11-17-40.png"|relative_url}})

**微调策略**直接照搬了[Spatial-temporal large language model for traffic prediction](https://arxiv.org/abs/2401.10134)的PFA LLM模块

![](../images/2025-12-09-11-22-33.png)
![]({{"../images/2025-12-09-11-22-33.png"|relative_url}})

![](../images/2025-12-09-11-25-35.png)
![]({{"../images/2025-12-09-11-25-35.png"|relative_url}})

**Test Time Adaptation**：针对zero-shot场景，对LLM生成的潜在嵌入做掩码，依然是采用MAE的掩码重建策略调整预测模块的准确性。

![](../images/2025-12-09-14-20-04.png)
![]({{"../images/2025-12-09-14-20-04.png"|relative_url}})


**文章**：LLM4HRS: LLM-Based Spatiotemporal Imputation  Model for Highly Sparse Remote Sensing Data
(IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 1区期刊). Code:[https://github.com/ssyuwang/LLM4HRS-master](https://github.com/ssyuwang/LLM4HRS-master，代码开源，但数据集无权限下载？)

**长江口数据稀疏性**：

![](../images/2025-12-04-10-38-37.png)
![]({{"../images/2025-12-04-10-38-37.png"|relative_url}})

**重点解决的两个问题**：

**问题1：双向时间依赖关系**

![](../images/2025-12-04-10-40-22.png)
![]({{"../images/2025-12-04-10-40-22.png"|relative_url}})

**问题2：高度空间相关性，邻居区域的分布较为相似**

![](../images/2025-12-04-10-41-14.png)
![]({{"../images/2025-12-04-10-41-14.png"|relative_url}})

**目标：使用LLM-Based模型进行稀疏遥感数据的插补**

**模型结构**

![](../images/2025-12-04-13-16-12.png)
![]({{"../images/2025-12-04-13-16-12.png"|relative_url}})

使用的预训练模型为GPT-2，冻结多头注意力层和前馈神经网络层，源于其他文章的思想（跟UrbanMind一样，照搬的）。

![](../images/2025-12-04-13-43-49.png)
![]({{"../images/2025-12-04-13-43-49.png"|relative_url}})

创新性一般，基本上数据已有技术的大杂烩，用于数据补全任务。


**文章**：Li Z, Chen T, Xu Y. AirGPT: Spatio-temporal large language model for air quality prediction[J]. Information Fusion, 2025: 103730. Code:[https://huggingface.co/bjdwh/AirGPT/tree/main](https://huggingface.co/bjdwh/AirGPT/tree/main)

试图解决的问题：

1. 稀疏数据问题，zero-shot场景预测
2. 多源数据融合
3. **可解释性差**

![](../images/2025-12-10-09-56-15.png)
![]({{"../images/2025-12-10-09-56-15.png"|relative_url}})

***引入时空融合指令调整范式，融合多源时空数据，以提高模型预测的精度；引入精细化的时空提示和思维链蒸馏机制提高模型的可解释性。***

![](../images/2025-12-10-10-59-09.png)
![]({{"../images/2025-12-10-10-59-09.png"|relative_url}})

利用地理位置构建静态时空图；结合地理位置和风速，风向构建动态时空图。

$$
静态图：A_{i,j}^{st} = \exp \left( -\frac{d_{i j}^{2}}{2\sigma^{2}} \right), \quad i \neq j
$$

$$
动态图：A_{t,i,j}^{dy} = \exp \left( -\frac{d_{i j}^{2}}{2(\sigma_{0} + \alpha v_{t})^{2}} \right) \cdot \cos(\Delta\Phi_{t,i,j}), \quad i \neq j
$$

使用全连接层->多头自注意力->Feed-Forward Network(激活函数： $\text{SiLU}(x) = x \cdot \sigma(x)$)捕获时空特征，

$$
\mathbf{H}_{S} = \operatorname{LeakyReLU}(A \mathbf{x} W_{S})
$$

其中，A代替静态图和动态图，分别获得静态和动态的空间嵌入，其后，通过门控机制融合两种嵌入表示：

$$
\begin{aligned}
Z &= \operatorname{sigmoid}(\mathbf{H}_{S}^{st} W_{g 1} + \mathbf{H}_{S}^{dy} W_{g 2}) \\
\overline{\mathbf{H}} &= (\mathbf{Z} \odot (\mathbf{H}_{st} W_{g 1}) + (1 - \mathbf{Z}) \odot (\mathbf{H}_{dy} W_{g 2})) \overline{W}
\end{aligned}
$$

示意图：

![](../images/2025-12-10-11-34-30.png)
![]({{"../images/2025-12-10-11-34-30.png"|relative_url}})

一层全连接层进行特征对齐（轻量化）。

![](../images/2025-12-10-14-29-50.png)
![]({{"../images/2025-12-10-14-29-50.png"|relative_url}})

可解释性-思维链蒸馏。将推理定义为了五个阶段：1.问题定义：阐明预测任务的核心参数->2.天气模式外推：从历史数据推测未来气象趋势->3.关键信息汇总：汇总所有相关输入变量->4.逐因素影响分析：系统评估每个决定因素对空气质量结果的单独积极和消极贡献->5.综合和预测结论：基于所有先前分析阶段的综合，制定最终的综合结论和相应的数值预测。

（奇怪）**基于标签约束的推理生成**：模型不负责预测，直接将ground-truth直接告诉模型，要模型生成合理的推理过程，以训练模型的推理能力，从而微调学生模型。（感觉不太合理，不一定是真实的因果推理机制，可能为了推出ground-truth去硬说）

![](../images/2025-12-10-14-50-25.png)
![]({{"../images/2025-12-10-14-50-25.png"|relative_url}})
